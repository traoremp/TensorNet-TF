/content/TensorNet-TF/experiments/mnist/FC-Tensorizing-Neural-Networks/tt-layer_and_quantization
/content/TensorNet-TF/experiments/mnist/FC-Tensorizing-Neural-Networks/tt-layer_and_quantization
2020-05-14 05:11:33.437576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
W0514 05:11:35.403343 140239982409600 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2020-05-14 05:11:35.516036: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-14 05:11:35.560351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 05:11:35.560917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-05-14 05:11:35.560957: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-14 05:11:35.841984: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-14 05:11:35.970162: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-14 05:11:35.998754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-14 05:11:36.264406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-14 05:11:36.300418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-14 05:11:36.780906: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-14 05:11:36.781076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 05:11:36.781746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 05:11:36.782240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
WARNING:tensorflow:From /content/TensorNet-TF/experiments/mnist/FC-Tensorizing-Neural-Networks/tt-layer_and_quantization/net.py:84: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0514 05:11:36.815829 140239982409600 deprecation.py:323] From /content/TensorNet-TF/experiments/mnist/FC-Tensorizing-Neural-Networks/tt-layer_and_quantization/net.py:84: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /content/TensorNet-TF/experiments/mnist/FC-Tensorizing-Neural-Networks/tt-layer_and_quantization/net.py:108: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0514 05:11:36.817581 140239982409600 deprecation.py:506] From /content/TensorNet-TF/experiments/mnist/FC-Tensorizing-Neural-Networks/tt-layer_and_quantization/net.py:108: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /content/TensorNet-TF/experiments/mnist/FC-Tensorizing-Neural-Networks/tt-layer_and_quantization/net.py:135: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W0514 05:11:37.057547 140239982409600 deprecation.py:323] From /content/TensorNet-TF/experiments/mnist/FC-Tensorizing-Neural-Networks/tt-layer_and_quantization/net.py:135: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /content/TensorNet-TF/experiments/mnist/FC-Tensorizing-Neural-Networks/tt-layer_and_quantization/net.py:140: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0514 05:11:37.058682 140239982409600 deprecation.py:323] From /content/TensorNet-TF/experiments/mnist/FC-Tensorizing-Neural-Networks/tt-layer_and_quantization/net.py:140: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

2020-05-14 05:11:37.628721: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-05-14 05:11:37.644139: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2000175000 Hz
2020-05-14 05:11:37.644535: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x32912c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-14 05:11:37.644571: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-05-14 05:11:37.782448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 05:11:37.783238: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3290f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-05-14 05:11:37.783268: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0
2020-05-14 05:11:37.784865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 05:11:37.785391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-05-14 05:11:37.785440: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-14 05:11:37.785491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-14 05:11:37.785525: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-14 05:11:37.785543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-14 05:11:37.785560: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-14 05:11:37.785576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-14 05:11:37.785593: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-14 05:11:37.785662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 05:11:37.786166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 05:11:37.786658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-05-14 05:11:37.790465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-14 05:11:44.159148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-14 05:11:44.159203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-05-14 05:11:44.159216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-05-14 05:11:44.160844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 05:11:44.161491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 05:11:44.162008: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-05-14 05:11:44.162049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)
2020-05-14 05:11:44.895008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
Step 100: loss = 2.66 (0.363 sec) [275.51 data/s]
Step 200: loss = 2.45 (0.362 sec) [275.89 data/s]
Step 300: loss = 2.30 (0.365 sec) [274.05 data/s]
Step 400: loss = 1.75 (0.365 sec) [273.72 data/s]
Step 500: loss = 1.45 (0.364 sec) [274.85 data/s]
Step 600: loss = 1.61 (0.362 sec) [276.30 data/s]
Step 700: loss = 1.41 (0.363 sec) [275.61 data/s]
Step 800: loss = 1.24 (0.362 sec) [275.99 data/s]
Step 900: loss = 1.16 (0.364 sec) [274.65 data/s]
Step 1000: loss = 1.27 (0.363 sec) [275.56 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 46708  Precision @ 1: 0.7785  Loss: 0.71
Validation Data Eval:
  Num examples: 10000  Num correct: 7888  Precision @ 1: 0.7888  Loss: 0.68
Step 1100: loss = 1.19 (0.363 sec) [275.42 data/s]
Step 1200: loss = 1.07 (0.363 sec) [275.73 data/s]
Step 1300: loss = 1.08 (0.364 sec) [274.51 data/s]
Step 1400: loss = 1.26 (0.363 sec) [275.42 data/s]
Step 1500: loss = 1.21 (0.363 sec) [275.49 data/s]
Step 1600: loss = 1.11 (0.363 sec) [275.24 data/s]
Step 1700: loss = 0.90 (0.363 sec) [275.60 data/s]
Step 1800: loss = 1.02 (0.365 sec) [274.01 data/s]
Step 1900: loss = 1.19 (0.365 sec) [274.03 data/s]
Step 2000: loss = 0.97 (0.363 sec) [275.68 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 49224  Precision @ 1: 0.8204  Loss: 0.62
Validation Data Eval:
  Num examples: 10000  Num correct: 8308  Precision @ 1: 0.8308  Loss: 0.58
Step 2100: loss = 0.97 (0.363 sec) [275.56 data/s]
Step 2200: loss = 1.17 (0.363 sec) [275.43 data/s]
Step 2300: loss = 0.96 (0.364 sec) [274.41 data/s]
Step 2400: loss = 1.06 (0.363 sec) [275.25 data/s]
Step 2500: loss = 0.82 (0.362 sec) [275.91 data/s]
Step 2600: loss = 0.91 (0.366 sec) [273.55 data/s]
Step 2700: loss = 0.80 (0.365 sec) [274.16 data/s]
Step 2800: loss = 1.00 (0.363 sec) [275.21 data/s]
Step 2900: loss = 0.89 (0.364 sec) [274.59 data/s]
Step 3000: loss = 1.12 (0.363 sec) [275.44 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 50566  Precision @ 1: 0.8428  Loss: 0.56
Validation Data Eval:
  Num examples: 10000  Num correct: 8488  Precision @ 1: 0.8488  Loss: 0.52
Step 3100: loss = 0.79 (0.362 sec) [276.00 data/s]
Step 3200: loss = 0.83 (0.363 sec) [275.43 data/s]
Step 3300: loss = 0.81 (0.362 sec) [275.99 data/s]
Step 3400: loss = 0.74 (0.366 sec) [273.23 data/s]
Step 3500: loss = 0.81 (0.363 sec) [275.37 data/s]
Step 3600: loss = 1.06 (0.363 sec) [275.21 data/s]
Step 3700: loss = 0.58 (0.363 sec) [275.44 data/s]
Step 3800: loss = 0.95 (0.366 sec) [273.55 data/s]
Step 3900: loss = 0.89 (0.363 sec) [275.45 data/s]
Step 4000: loss = 0.93 (0.363 sec) [275.27 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 51335  Precision @ 1: 0.8556  Loss: 0.52
Validation Data Eval:
  Num examples: 10000  Num correct: 8613  Precision @ 1: 0.8613  Loss: 0.50
Step 4100: loss = 0.84 (0.363 sec) [275.34 data/s]
Step 4200: loss = 0.79 (0.363 sec) [275.29 data/s]
Step 4300: loss = 1.07 (0.363 sec) [275.64 data/s]
Step 4400: loss = 0.63 (0.363 sec) [275.78 data/s]
Step 4500: loss = 0.60 (0.363 sec) [275.12 data/s]
Step 4600: loss = 0.89 (0.363 sec) [275.66 data/s]
Step 4700: loss = 0.83 (0.363 sec) [275.66 data/s]
Step 4800: loss = 0.97 (0.363 sec) [275.29 data/s]
Step 4900: loss = 0.65 (0.363 sec) [275.50 data/s]
Step 5000: loss = 0.72 (0.363 sec) [275.75 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 51833  Precision @ 1: 0.8639  Loss: 0.50
Validation Data Eval:
  Num examples: 10000  Num correct: 8764  Precision @ 1: 0.8764  Loss: 0.47
Step 5100: loss = 0.56 (0.365 sec) [274.33 data/s]
Step 5200: loss = 0.50 (0.363 sec) [275.38 data/s]
Step 5300: loss = 0.76 (0.363 sec) [275.77 data/s]
Step 5400: loss = 0.52 (0.363 sec) [275.38 data/s]
Step 5500: loss = 0.65 (0.363 sec) [275.57 data/s]
Step 5600: loss = 0.65 (0.365 sec) [273.67 data/s]
Step 5700: loss = 0.66 (0.365 sec) [274.33 data/s]
Step 5800: loss = 0.98 (0.362 sec) [275.93 data/s]
Step 5900: loss = 0.57 (0.363 sec) [275.54 data/s]
Step 6000: loss = 0.89 (0.365 sec) [273.99 data/s]
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0514 05:55:56.130899 140239982409600 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Training Data Eval:
  Num examples: 60000  Num correct: 52275  Precision @ 1: 0.8712  Loss: 0.48
Validation Data Eval:
  Num examples: 10000  Num correct: 8773  Precision @ 1: 0.8773  Loss: 0.46
Step 6100: loss = 0.56 (0.363 sec) [275.51 data/s]
Step 6200: loss = 0.77 (0.363 sec) [275.69 data/s]
Step 6300: loss = 0.60 (0.368 sec) [271.63 data/s]
Step 6400: loss = 0.71 (0.363 sec) [275.31 data/s]
Step 6500: loss = 0.74 (0.364 sec) [275.05 data/s]
Step 6600: loss = 0.36 (0.363 sec) [275.43 data/s]
Step 6700: loss = 0.53 (0.364 sec) [275.10 data/s]
Step 6800: loss = 0.77 (0.364 sec) [275.09 data/s]
Step 6900: loss = 0.70 (0.363 sec) [275.20 data/s]
Step 7000: loss = 0.68 (0.362 sec) [275.92 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 52578  Precision @ 1: 0.8763  Loss: 0.46
Validation Data Eval:
  Num examples: 10000  Num correct: 8866  Precision @ 1: 0.8866  Loss: 0.43
Step 7100: loss = 0.75 (0.364 sec) [275.04 data/s]
Step 7200: loss = 0.67 (0.363 sec) [275.82 data/s]
Step 7300: loss = 0.72 (0.363 sec) [275.21 data/s]
Step 7400: loss = 0.70 (0.364 sec) [274.99 data/s]
Step 7500: loss = 0.43 (0.365 sec) [274.13 data/s]
Step 7600: loss = 0.69 (0.363 sec) [275.54 data/s]
Step 7700: loss = 0.64 (0.363 sec) [275.47 data/s]
Step 7800: loss = 0.52 (0.365 sec) [274.19 data/s]
Step 7900: loss = 0.73 (0.363 sec) [275.23 data/s]
Step 8000: loss = 0.72 (0.363 sec) [275.62 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 52686  Precision @ 1: 0.8781  Loss: 0.46
Validation Data Eval:
  Num examples: 10000  Num correct: 8849  Precision @ 1: 0.8849  Loss: 0.44
Step 8100: loss = 0.61 (0.365 sec) [274.02 data/s]
Step 8200: loss = 0.44 (0.363 sec) [275.57 data/s]
Step 8300: loss = 0.78 (0.363 sec) [275.20 data/s]
Step 8400: loss = 0.46 (0.363 sec) [275.63 data/s]
Step 8500: loss = 0.52 (0.362 sec) [275.98 data/s]
Step 8600: loss = 0.66 (0.362 sec) [276.15 data/s]
Step 8700: loss = 0.70 (0.365 sec) [274.13 data/s]
Step 8800: loss = 0.74 (0.365 sec) [274.00 data/s]
Step 8900: loss = 0.71 (0.363 sec) [275.43 data/s]
Step 9000: loss = 0.45 (0.364 sec) [274.62 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 52928  Precision @ 1: 0.8821  Loss: 0.44
Validation Data Eval:
  Num examples: 10000  Num correct: 8894  Precision @ 1: 0.8894  Loss: 0.42
Step 9100: loss = 0.70 (0.363 sec) [275.26 data/s]
Step 9200: loss = 0.67 (0.364 sec) [275.05 data/s]
Step 9300: loss = 0.70 (0.363 sec) [275.13 data/s]
Step 9400: loss = 0.69 (0.365 sec) [273.92 data/s]
Step 9500: loss = 0.66 (0.363 sec) [275.44 data/s]
Step 9600: loss = 0.65 (0.366 sec) [272.86 data/s]
Step 9700: loss = 0.74 (0.363 sec) [275.56 data/s]
Step 9800: loss = 0.63 (0.364 sec) [275.03 data/s]
Step 9900: loss = 0.82 (0.363 sec) [275.78 data/s]
Step 10000: loss = 0.61 (0.363 sec) [275.17 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53007  Precision @ 1: 0.8834  Loss: 0.44
Validation Data Eval:
  Num examples: 10000  Num correct: 8926  Precision @ 1: 0.8926  Loss: 0.42
Step 10100: loss = 0.50 (0.363 sec) [275.36 data/s]
Step 10200: loss = 0.63 (0.363 sec) [275.81 data/s]
Step 10300: loss = 0.60 (0.363 sec) [275.18 data/s]
Step 10400: loss = 0.39 (0.363 sec) [275.28 data/s]
Step 10500: loss = 0.51 (0.365 sec) [274.02 data/s]
Step 10600: loss = 0.41 (0.363 sec) [275.21 data/s]
Step 10700: loss = 0.61 (0.363 sec) [275.45 data/s]
Step 10800: loss = 0.41 (0.363 sec) [275.39 data/s]
Step 10900: loss = 0.71 (0.363 sec) [275.74 data/s]
Step 11000: loss = 0.50 (0.363 sec) [275.62 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53044  Precision @ 1: 0.8841  Loss: 0.44
Validation Data Eval:
  Num examples: 10000  Num correct: 8910  Precision @ 1: 0.8910  Loss: 0.41
Step 11100: loss = 0.61 (0.363 sec) [275.50 data/s]
Step 11200: loss = 0.62 (0.363 sec) [275.48 data/s]
Step 11300: loss = 0.69 (0.362 sec) [275.90 data/s]
Step 11400: loss = 0.65 (0.365 sec) [274.00 data/s]
Step 11500: loss = 0.58 (0.363 sec) [275.80 data/s]
Step 11600: loss = 0.63 (0.363 sec) [275.49 data/s]
Step 11700: loss = 0.78 (0.365 sec) [274.34 data/s]
Step 11800: loss = 0.94 (0.363 sec) [275.15 data/s]
Step 11900: loss = 0.64 (0.365 sec) [273.96 data/s]
Step 12000: loss = 0.66 (0.363 sec) [275.73 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 52955  Precision @ 1: 0.8826  Loss: 0.44
Validation Data Eval:
  Num examples: 10000  Num correct: 8858  Precision @ 1: 0.8858  Loss: 0.42
Step 12100: loss = 0.72 (0.365 sec) [274.21 data/s]
Step 12200: loss = 0.57 (0.362 sec) [275.88 data/s]
Step 12300: loss = 0.47 (0.363 sec) [275.83 data/s]
Step 12400: loss = 0.38 (0.362 sec) [276.01 data/s]
Step 12500: loss = 0.59 (0.364 sec) [275.05 data/s]
Step 12600: loss = 0.84 (0.363 sec) [275.73 data/s]
Step 12700: loss = 0.43 (0.365 sec) [273.95 data/s]
Step 12800: loss = 0.67 (0.363 sec) [275.42 data/s]
Step 12900: loss = 0.60 (0.363 sec) [275.33 data/s]
Step 13000: loss = 0.49 (0.365 sec) [274.31 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 52842  Precision @ 1: 0.8807  Loss: 0.45
Validation Data Eval:
  Num examples: 10000  Num correct: 8888  Precision @ 1: 0.8888  Loss: 0.43
Step 13100: loss = 0.64 (0.363 sec) [275.61 data/s]
Step 13200: loss = 0.69 (0.363 sec) [275.43 data/s]
Step 13300: loss = 0.68 (0.362 sec) [276.00 data/s]
Step 13400: loss = 0.66 (0.363 sec) [275.14 data/s]
Step 13500: loss = 0.41 (0.362 sec) [275.98 data/s]
Step 13600: loss = 0.80 (0.364 sec) [274.42 data/s]
Step 13700: loss = 0.69 (0.365 sec) [273.66 data/s]
Step 13800: loss = 0.48 (0.363 sec) [275.13 data/s]
Step 13900: loss = 0.51 (0.364 sec) [274.59 data/s]
Step 14000: loss = 0.57 (0.365 sec) [274.30 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 52951  Precision @ 1: 0.8825  Loss: 0.46
Validation Data Eval:
  Num examples: 10000  Num correct: 8883  Precision @ 1: 0.8883  Loss: 0.44
Step 14100: loss = 0.44 (0.363 sec) [275.16 data/s]
Step 14200: loss = 0.54 (0.363 sec) [275.23 data/s]
Step 14300: loss = 0.62 (0.363 sec) [275.54 data/s]
Step 14400: loss = 0.58 (0.363 sec) [275.52 data/s]
Step 14500: loss = 0.54 (0.365 sec) [274.08 data/s]
Step 14600: loss = 0.61 (0.363 sec) [275.49 data/s]
Step 14700: loss = 0.46 (0.363 sec) [275.59 data/s]
Step 14800: loss = 0.92 (0.363 sec) [275.52 data/s]
Step 14900: loss = 0.79 (0.362 sec) [275.87 data/s]
Step 15000: loss = 0.70 (0.363 sec) [275.80 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53569  Precision @ 1: 0.8928  Loss: 0.41
Validation Data Eval:
  Num examples: 10000  Num correct: 8973  Precision @ 1: 0.8973  Loss: 0.39
Step 15100: loss = 0.58 (0.362 sec) [275.89 data/s]
Step 15200: loss = 0.63 (0.364 sec) [275.01 data/s]
Step 15300: loss = 0.71 (0.363 sec) [275.84 data/s]
Step 15400: loss = 0.78 (0.363 sec) [275.14 data/s]
Step 15500: loss = 0.50 (0.363 sec) [275.29 data/s]
Step 15600: loss = 0.51 (0.363 sec) [275.43 data/s]
Step 15700: loss = 0.73 (0.366 sec) [273.41 data/s]
Step 15800: loss = 0.68 (0.363 sec) [275.44 data/s]
Step 15900: loss = 0.48 (0.363 sec) [275.33 data/s]
Step 16000: loss = 0.64 (0.365 sec) [274.07 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53137  Precision @ 1: 0.8856  Loss: 0.45
Validation Data Eval:
  Num examples: 10000  Num correct: 8890  Precision @ 1: 0.8890  Loss: 0.43
Step 16100: loss = 0.73 (0.363 sec) [275.56 data/s]
Step 16200: loss = 0.56 (0.363 sec) [275.16 data/s]
Step 16300: loss = 0.70 (0.365 sec) [273.73 data/s]
Step 16400: loss = 0.58 (0.362 sec) [275.87 data/s]
Step 16500: loss = 0.80 (0.363 sec) [275.29 data/s]
Step 16600: loss = 0.61 (0.363 sec) [275.15 data/s]
Step 16700: loss = 0.77 (0.364 sec) [274.58 data/s]
Step 16800: loss = 0.66 (0.363 sec) [275.34 data/s]
Step 16900: loss = 0.84 (0.363 sec) [275.50 data/s]
Step 17000: loss = 0.43 (0.363 sec) [275.24 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53608  Precision @ 1: 0.8935  Loss: 0.41
Validation Data Eval:
  Num examples: 10000  Num correct: 8990  Precision @ 1: 0.8990  Loss: 0.39
Step 17100: loss = 0.48 (0.363 sec) [275.47 data/s]
Step 17200: loss = 0.55 (0.364 sec) [274.82 data/s]
Step 17300: loss = 0.78 (0.365 sec) [273.95 data/s]
Step 17400: loss = 0.56 (0.363 sec) [275.18 data/s]
Step 17500: loss = 0.56 (0.363 sec) [275.53 data/s]
Step 17600: loss = 0.43 (0.364 sec) [274.96 data/s]
Step 17700: loss = 0.49 (0.365 sec) [273.76 data/s]
Step 17800: loss = 0.61 (0.363 sec) [275.40 data/s]
Step 17900: loss = 0.37 (0.363 sec) [275.34 data/s]
Step 18000: loss = 0.35 (0.369 sec) [270.91 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53387  Precision @ 1: 0.8898  Loss: 0.41
Validation Data Eval:
  Num examples: 10000  Num correct: 8953  Precision @ 1: 0.8953  Loss: 0.39
Step 18100: loss = 0.51 (0.363 sec) [275.18 data/s]
Step 18200: loss = 0.48 (0.363 sec) [275.34 data/s]
Step 18300: loss = 0.59 (0.364 sec) [274.73 data/s]
Step 18400: loss = 0.51 (0.363 sec) [275.70 data/s]
Step 18500: loss = 0.92 (0.364 sec) [274.96 data/s]
Step 18600: loss = 0.44 (0.364 sec) [274.60 data/s]
Step 18700: loss = 0.78 (0.364 sec) [275.06 data/s]
Step 18800: loss = 0.52 (0.364 sec) [274.43 data/s]
Step 18900: loss = 0.34 (0.363 sec) [275.36 data/s]
Step 19000: loss = 0.38 (0.364 sec) [274.72 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53339  Precision @ 1: 0.8890  Loss: 0.42
Validation Data Eval:
  Num examples: 10000  Num correct: 8966  Precision @ 1: 0.8966  Loss: 0.40
Step 19100: loss = 0.42 (0.363 sec) [275.37 data/s]
Step 19200: loss = 0.48 (0.364 sec) [274.59 data/s]
Step 19300: loss = 0.70 (0.363 sec) [275.77 data/s]
Step 19400: loss = 0.53 (0.363 sec) [275.24 data/s]
Step 19500: loss = 0.44 (0.363 sec) [275.14 data/s]
Step 19600: loss = 0.56 (0.363 sec) [275.66 data/s]
Step 19700: loss = 0.63 (0.364 sec) [274.55 data/s]
Step 19800: loss = 0.46 (0.363 sec) [275.25 data/s]
Step 19900: loss = 0.43 (0.364 sec) [274.83 data/s]
Step 20000: loss = 0.68 (0.364 sec) [274.36 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53771  Precision @ 1: 0.8962  Loss: 0.40
Validation Data Eval:
  Num examples: 10000  Num correct: 9025  Precision @ 1: 0.9025  Loss: 0.38
Step 20100: loss = 0.47 (0.363 sec) [275.35 data/s]
Step 20200: loss = 0.67 (0.363 sec) [275.31 data/s]
Step 20300: loss = 0.54 (0.363 sec) [275.21 data/s]
Step 20400: loss = 0.63 (0.364 sec) [275.05 data/s]
Step 20500: loss = 0.55 (0.363 sec) [275.42 data/s]
Step 20600: loss = 0.48 (0.365 sec) [273.75 data/s]
Step 20700: loss = 0.40 (0.363 sec) [275.15 data/s]
Step 20800: loss = 0.43 (0.363 sec) [275.24 data/s]
Step 20900: loss = 0.64 (0.363 sec) [275.12 data/s]
Step 21000: loss = 0.46 (0.365 sec) [274.34 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53736  Precision @ 1: 0.8956  Loss: 0.39
Validation Data Eval:
  Num examples: 10000  Num correct: 9026  Precision @ 1: 0.9026  Loss: 0.37
Step 21100: loss = 0.39 (0.364 sec) [274.97 data/s]
Step 21200: loss = 0.52 (0.363 sec) [275.31 data/s]
Step 21300: loss = 0.39 (0.366 sec) [273.14 data/s]
Step 21400: loss = 0.46 (0.365 sec) [274.31 data/s]
Step 21500: loss = 0.29 (0.363 sec) [275.35 data/s]
Step 21600: loss = 0.65 (0.364 sec) [274.77 data/s]
Step 21700: loss = 0.63 (0.363 sec) [275.35 data/s]
Step 21800: loss = 0.74 (0.365 sec) [273.90 data/s]
Step 21900: loss = 0.53 (0.364 sec) [274.78 data/s]
Step 22000: loss = 0.34 (0.363 sec) [275.24 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53854  Precision @ 1: 0.8976  Loss: 0.38
Validation Data Eval:
  Num examples: 10000  Num correct: 9024  Precision @ 1: 0.9024  Loss: 0.37
Step 22100: loss = 0.38 (0.365 sec) [273.95 data/s]
Step 22200: loss = 0.43 (0.363 sec) [275.33 data/s]
Step 22300: loss = 0.49 (0.363 sec) [275.20 data/s]
Step 22400: loss = 0.53 (0.363 sec) [275.57 data/s]
Step 22500: loss = 0.32 (0.364 sec) [274.84 data/s]
Step 22600: loss = 0.67 (0.363 sec) [275.24 data/s]
Step 22700: loss = 0.38 (0.363 sec) [275.40 data/s]
Step 22800: loss = 0.54 (0.364 sec) [274.86 data/s]
Step 22900: loss = 0.45 (0.364 sec) [274.87 data/s]
Step 23000: loss = 0.64 (0.363 sec) [275.47 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53811  Precision @ 1: 0.8969  Loss: 0.39
Validation Data Eval:
  Num examples: 10000  Num correct: 9000  Precision @ 1: 0.9000  Loss: 0.38
Step 23100: loss = 0.57 (0.365 sec) [273.85 data/s]
Step 23200: loss = 0.53 (0.363 sec) [275.17 data/s]
Step 23300: loss = 0.49 (0.363 sec) [275.37 data/s]
Step 23400: loss = 0.45 (0.363 sec) [275.39 data/s]
Step 23500: loss = 0.40 (0.363 sec) [275.47 data/s]
Step 23600: loss = 0.31 (0.365 sec) [274.24 data/s]
Step 23700: loss = 0.46 (0.363 sec) [275.13 data/s]
Step 23800: loss = 0.72 (0.363 sec) [275.51 data/s]
Step 23900: loss = 0.40 (0.364 sec) [274.82 data/s]
Step 24000: loss = 0.51 (0.362 sec) [275.99 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53834  Precision @ 1: 0.8972  Loss: 0.39
Validation Data Eval:
  Num examples: 10000  Num correct: 9043  Precision @ 1: 0.9043  Loss: 0.37
Step 24100: loss = 0.43 (0.364 sec) [274.96 data/s]
Step 24200: loss = 0.60 (0.363 sec) [275.16 data/s]
Step 24300: loss = 0.35 (0.363 sec) [275.57 data/s]
Step 24400: loss = 0.52 (0.366 sec) [273.54 data/s]
Step 24500: loss = 0.76 (0.363 sec) [275.35 data/s]
Step 24600: loss = 0.42 (0.363 sec) [275.21 data/s]
Step 24700: loss = 0.45 (0.365 sec) [274.02 data/s]
Step 24800: loss = 0.48 (0.364 sec) [274.75 data/s]
Step 24900: loss = 0.53 (0.363 sec) [275.33 data/s]
Step 25000: loss = 0.57 (0.365 sec) [273.90 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54130  Precision @ 1: 0.9022  Loss: 0.37
Validation Data Eval:
  Num examples: 10000  Num correct: 9043  Precision @ 1: 0.9043  Loss: 0.36
Step 25100: loss = 0.41 (0.363 sec) [275.23 data/s]
Step 25200: loss = 0.54 (0.363 sec) [275.27 data/s]
Step 25300: loss = 0.50 (0.364 sec) [274.75 data/s]
Step 25400: loss = 0.49 (0.363 sec) [275.83 data/s]
Step 25500: loss = 0.53 (0.363 sec) [275.18 data/s]
Step 25600: loss = 0.49 (0.364 sec) [274.82 data/s]
Step 25700: loss = 0.62 (0.363 sec) [275.37 data/s]
Step 25800: loss = 0.71 (0.366 sec) [273.47 data/s]
Step 25900: loss = 0.39 (0.364 sec) [274.99 data/s]
Step 26000: loss = 0.54 (0.365 sec) [273.85 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53854  Precision @ 1: 0.8976  Loss: 0.38
Validation Data Eval:
  Num examples: 10000  Num correct: 9027  Precision @ 1: 0.9027  Loss: 0.37
Step 26100: loss = 0.51 (0.363 sec) [275.42 data/s]
Step 26200: loss = 0.49 (0.363 sec) [275.32 data/s]
Step 26300: loss = 0.55 (0.363 sec) [275.20 data/s]
Step 26400: loss = 0.45 (0.364 sec) [274.58 data/s]
Step 26500: loss = 0.45 (0.363 sec) [275.50 data/s]
Step 26600: loss = 0.62 (0.363 sec) [275.31 data/s]
Step 26700: loss = 0.54 (0.363 sec) [275.46 data/s]
Step 26800: loss = 0.53 (0.366 sec) [273.56 data/s]
Step 26900: loss = 0.45 (0.363 sec) [275.23 data/s]
Step 27000: loss = 0.42 (0.364 sec) [274.91 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53772  Precision @ 1: 0.8962  Loss: 0.38
Validation Data Eval:
  Num examples: 10000  Num correct: 9020  Precision @ 1: 0.9020  Loss: 0.37
Step 27100: loss = 0.38 (0.363 sec) [275.15 data/s]
Step 27200: loss = 0.47 (0.366 sec) [273.34 data/s]
Step 27300: loss = 0.78 (0.365 sec) [273.88 data/s]
Step 27400: loss = 0.28 (0.365 sec) [274.21 data/s]
Step 27500: loss = 0.66 (0.363 sec) [275.22 data/s]
Step 27600: loss = 0.40 (0.364 sec) [275.04 data/s]
Step 27700: loss = 0.45 (0.363 sec) [275.82 data/s]
Step 27800: loss = 0.55 (0.363 sec) [275.35 data/s]
Step 27900: loss = 0.44 (0.364 sec) [274.96 data/s]
Step 28000: loss = 0.40 (0.363 sec) [275.11 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54133  Precision @ 1: 0.9022  Loss: 0.37
Validation Data Eval:
  Num examples: 10000  Num correct: 9100  Precision @ 1: 0.9100  Loss: 0.35
Step 28100: loss = 0.40 (0.363 sec) [275.14 data/s]
Step 28200: loss = 0.57 (0.363 sec) [275.12 data/s]
Step 28300: loss = 0.45 (0.363 sec) [275.15 data/s]
Step 28400: loss = 0.38 (0.364 sec) [275.09 data/s]
Step 28500: loss = 0.56 (0.363 sec) [275.29 data/s]
Step 28600: loss = 0.41 (0.363 sec) [275.43 data/s]
Step 28700: loss = 0.41 (0.363 sec) [275.23 data/s]
Step 28800: loss = 0.46 (0.363 sec) [275.59 data/s]
Step 28900: loss = 0.70 (0.363 sec) [275.33 data/s]
Step 29000: loss = 0.46 (0.363 sec) [275.69 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53931  Precision @ 1: 0.8989  Loss: 0.37
Validation Data Eval:
  Num examples: 10000  Num correct: 9053  Precision @ 1: 0.9053  Loss: 0.36
Step 29100: loss = 0.45 (0.366 sec) [273.54 data/s]
Step 29200: loss = 0.35 (0.364 sec) [275.08 data/s]
Step 29300: loss = 0.56 (0.365 sec) [274.17 data/s]
Step 29400: loss = 0.36 (0.363 sec) [275.60 data/s]
Step 29500: loss = 0.35 (0.363 sec) [275.13 data/s]
Step 29600: loss = 0.59 (0.364 sec) [274.89 data/s]
Step 29700: loss = 0.81 (0.365 sec) [274.12 data/s]
Step 29800: loss = 0.56 (0.363 sec) [275.26 data/s]
Step 29900: loss = 0.41 (0.364 sec) [274.97 data/s]
Step 30000: loss = 0.48 (0.366 sec) [273.29 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53557  Precision @ 1: 0.8926  Loss: 0.40
Validation Data Eval:
  Num examples: 10000  Num correct: 8960  Precision @ 1: 0.8960  Loss: 0.39
Step 30100: loss = 0.34 (0.364 sec) [274.84 data/s]
Step 30200: loss = 0.24 (0.364 sec) [275.02 data/s]
Step 30300: loss = 0.46 (0.364 sec) [274.87 data/s]
Step 30400: loss = 0.43 (0.364 sec) [274.67 data/s]
Step 30500: loss = 0.71 (0.363 sec) [275.38 data/s]
Step 30600: loss = 0.53 (0.363 sec) [275.38 data/s]
Step 30700: loss = 0.38 (0.364 sec) [275.05 data/s]
Step 30800: loss = 0.39 (0.365 sec) [273.95 data/s]
Step 30900: loss = 0.46 (0.363 sec) [275.12 data/s]
Step 31000: loss = 0.52 (0.365 sec) [274.22 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53612  Precision @ 1: 0.8935  Loss: 0.40
Validation Data Eval:
  Num examples: 10000  Num correct: 8955  Precision @ 1: 0.8955  Loss: 0.39
Step 31100: loss = 0.44 (0.363 sec) [275.19 data/s]
Step 31200: loss = 0.56 (0.363 sec) [275.37 data/s]
Step 31300: loss = 0.41 (0.363 sec) [275.37 data/s]
Step 31400: loss = 0.30 (0.365 sec) [273.89 data/s]
Step 31500: loss = 0.54 (0.364 sec) [275.08 data/s]
Step 31600: loss = 0.47 (0.363 sec) [275.27 data/s]
Step 31700: loss = 0.46 (0.363 sec) [275.49 data/s]
Step 31800: loss = 0.52 (0.365 sec) [273.61 data/s]
Step 31900: loss = 0.42 (0.363 sec) [275.15 data/s]
Step 32000: loss = 0.41 (0.364 sec) [274.94 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53774  Precision @ 1: 0.8962  Loss: 0.38
Validation Data Eval:
  Num examples: 10000  Num correct: 9016  Precision @ 1: 0.9016  Loss: 0.38
Step 32100: loss = 0.43 (0.364 sec) [274.46 data/s]
Step 32200: loss = 0.40 (0.364 sec) [275.00 data/s]
Step 32300: loss = 0.45 (0.364 sec) [274.41 data/s]
Step 32400: loss = 0.40 (0.363 sec) [275.49 data/s]
Step 32500: loss = 0.56 (0.363 sec) [275.10 data/s]
Step 32600: loss = 0.57 (0.365 sec) [273.78 data/s]
Step 32700: loss = 0.42 (0.363 sec) [275.29 data/s]
Step 32800: loss = 0.32 (0.364 sec) [274.71 data/s]
Step 32900: loss = 0.39 (0.363 sec) [275.19 data/s]
Step 33000: loss = 0.66 (0.364 sec) [274.86 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54007  Precision @ 1: 0.9001  Loss: 0.37
Validation Data Eval:
  Num examples: 10000  Num correct: 9025  Precision @ 1: 0.9025  Loss: 0.35
Step 33100: loss = 0.37 (0.364 sec) [274.63 data/s]
Step 33200: loss = 0.40 (0.364 sec) [274.71 data/s]
Step 33300: loss = 0.35 (0.363 sec) [275.32 data/s]
Step 33400: loss = 0.52 (0.364 sec) [274.72 data/s]
Step 33500: loss = 0.31 (0.366 sec) [273.57 data/s]
Step 33600: loss = 0.65 (0.365 sec) [273.78 data/s]
Step 33700: loss = 0.41 (0.364 sec) [274.60 data/s]
Step 33800: loss = 0.33 (0.365 sec) [274.04 data/s]
Step 33900: loss = 0.41 (0.363 sec) [275.26 data/s]
Step 34000: loss = 0.42 (0.364 sec) [274.71 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54037  Precision @ 1: 0.9006  Loss: 0.37
Validation Data Eval:
  Num examples: 10000  Num correct: 9032  Precision @ 1: 0.9032  Loss: 0.36
Step 34100: loss = 0.52 (0.364 sec) [274.89 data/s]
Step 34200: loss = 0.44 (0.364 sec) [275.04 data/s]
Step 34300: loss = 0.65 (0.363 sec) [275.27 data/s]
Step 34400: loss = 0.57 (0.363 sec) [275.16 data/s]
Step 34500: loss = 0.31 (0.364 sec) [275.00 data/s]
Step 34600: loss = 0.55 (0.363 sec) [275.31 data/s]
Step 34700: loss = 0.43 (0.364 sec) [274.76 data/s]
Step 34800: loss = 0.62 (0.364 sec) [274.53 data/s]
Step 34900: loss = 0.47 (0.363 sec) [275.44 data/s]
Step 35000: loss = 0.69 (0.364 sec) [274.95 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53400  Precision @ 1: 0.8900  Loss: 0.41
Validation Data Eval:
  Num examples: 10000  Num correct: 8950  Precision @ 1: 0.8950  Loss: 0.40
Step 35100: loss = 0.43 (0.364 sec) [274.64 data/s]
Step 35200: loss = 0.34 (0.363 sec) [275.25 data/s]
Step 35300: loss = 0.57 (0.364 sec) [274.96 data/s]
Step 35400: loss = 0.51 (0.363 sec) [275.27 data/s]
Step 35500: loss = 0.39 (0.363 sec) [275.39 data/s]
Step 35600: loss = 0.34 (0.364 sec) [274.57 data/s]
Step 35700: loss = 0.36 (0.363 sec) [275.28 data/s]
Step 35800: loss = 0.58 (0.365 sec) [273.77 data/s]
Step 35900: loss = 0.45 (0.363 sec) [275.30 data/s]
Step 36000: loss = 0.57 (0.363 sec) [275.51 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53979  Precision @ 1: 0.8996  Loss: 0.36
Validation Data Eval:
  Num examples: 10000  Num correct: 9039  Precision @ 1: 0.9039  Loss: 0.36
Step 36100: loss = 0.45 (0.363 sec) [275.41 data/s]
Step 36200: loss = 0.30 (0.364 sec) [275.07 data/s]
Step 36300: loss = 0.64 (0.364 sec) [275.04 data/s]
Step 36400: loss = 0.54 (0.363 sec) [275.46 data/s]
Step 36500: loss = 0.62 (0.363 sec) [275.24 data/s]
Step 36600: loss = 0.47 (0.363 sec) [275.40 data/s]
Step 36700: loss = 0.43 (0.363 sec) [275.19 data/s]
Step 36800: loss = 0.37 (0.363 sec) [275.55 data/s]
Step 36900: loss = 0.40 (0.363 sec) [275.65 data/s]
Step 37000: loss = 0.40 (0.363 sec) [275.79 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54053  Precision @ 1: 0.9009  Loss: 0.36
Validation Data Eval:
  Num examples: 10000  Num correct: 9054  Precision @ 1: 0.9054  Loss: 0.36
Step 37100: loss = 0.35 (0.363 sec) [275.28 data/s]
Step 37200: loss = 0.48 (0.363 sec) [275.69 data/s]
Step 37300: loss = 0.28 (0.364 sec) [275.09 data/s]
Step 37400: loss = 0.58 (0.365 sec) [274.11 data/s]
Step 37500: loss = 0.38 (0.363 sec) [275.58 data/s]
Step 37600: loss = 0.43 (0.363 sec) [275.59 data/s]
Step 37700: loss = 0.26 (0.363 sec) [275.71 data/s]
Step 37800: loss = 0.39 (0.363 sec) [275.30 data/s]
Step 37900: loss = 0.37 (0.365 sec) [274.11 data/s]
Step 38000: loss = 0.32 (0.364 sec) [274.76 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54272  Precision @ 1: 0.9045  Loss: 0.35
Validation Data Eval:
  Num examples: 10000  Num correct: 9078  Precision @ 1: 0.9078  Loss: 0.34
Step 38100: loss = 0.45 (0.363 sec) [275.21 data/s]
Step 38200: loss = 0.61 (0.363 sec) [275.73 data/s]
Step 38300: loss = 0.71 (0.363 sec) [275.11 data/s]
Step 38400: loss = 0.63 (0.363 sec) [275.77 data/s]
Step 38500: loss = 0.55 (0.365 sec) [273.74 data/s]
Step 38600: loss = 0.39 (0.363 sec) [275.30 data/s]
Step 38700: loss = 0.47 (0.363 sec) [275.30 data/s]
Step 38800: loss = 0.35 (0.362 sec) [275.87 data/s]
Step 38900: loss = 0.39 (0.363 sec) [275.52 data/s]
Step 39000: loss = 0.51 (0.363 sec) [275.25 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54119  Precision @ 1: 0.9020  Loss: 0.37
Validation Data Eval:
  Num examples: 10000  Num correct: 9085  Precision @ 1: 0.9085  Loss: 0.36
Step 39100: loss = 0.42 (0.365 sec) [274.03 data/s]
Step 39200: loss = 0.33 (0.365 sec) [273.91 data/s]
Step 39300: loss = 0.58 (0.364 sec) [274.43 data/s]
Step 39400: loss = 0.67 (0.365 sec) [274.10 data/s]
Step 39500: loss = 0.39 (0.364 sec) [274.99 data/s]
Step 39600: loss = 0.58 (0.364 sec) [275.01 data/s]
Step 39700: loss = 0.52 (0.363 sec) [275.47 data/s]
Step 39800: loss = 0.35 (0.364 sec) [275.03 data/s]
Step 39900: loss = 0.52 (0.366 sec) [273.04 data/s]
Step 40000: loss = 0.62 (0.363 sec) [275.69 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54063  Precision @ 1: 0.9011  Loss: 0.37
Validation Data Eval:
  Num examples: 10000  Num correct: 9061  Precision @ 1: 0.9061  Loss: 0.35
Step 40100: loss = 0.49 (0.363 sec) [275.37 data/s]
Step 40200: loss = 0.62 (0.363 sec) [275.63 data/s]
Step 40300: loss = 0.43 (0.363 sec) [275.36 data/s]
Step 40400: loss = 0.31 (0.363 sec) [275.43 data/s]
Step 40500: loss = 0.33 (0.363 sec) [275.43 data/s]
Step 40600: loss = 0.56 (0.365 sec) [273.73 data/s]
Step 40700: loss = 0.49 (0.363 sec) [275.47 data/s]
Step 40800: loss = 0.37 (0.363 sec) [275.65 data/s]
Step 40900: loss = 0.43 (0.362 sec) [275.96 data/s]
Step 41000: loss = 0.61 (0.363 sec) [275.36 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54261  Precision @ 1: 0.9043  Loss: 0.35
Validation Data Eval:
  Num examples: 10000  Num correct: 9090  Precision @ 1: 0.9090  Loss: 0.34
Step 41100: loss = 0.36 (0.364 sec) [275.10 data/s]
Step 41200: loss = 0.34 (0.363 sec) [275.56 data/s]
Step 41300: loss = 0.37 (0.363 sec) [275.17 data/s]
Step 41400: loss = 0.74 (0.363 sec) [275.44 data/s]
Step 41500: loss = 0.40 (0.363 sec) [275.21 data/s]
Step 41600: loss = 0.40 (0.365 sec) [273.88 data/s]
Step 41700: loss = 0.54 (0.363 sec) [275.46 data/s]
Step 41800: loss = 0.42 (0.363 sec) [275.48 data/s]
Step 41900: loss = 0.46 (0.363 sec) [275.37 data/s]
Step 42000: loss = 0.35 (0.363 sec) [275.51 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54288  Precision @ 1: 0.9048  Loss: 0.35
Validation Data Eval:
  Num examples: 10000  Num correct: 9106  Precision @ 1: 0.9106  Loss: 0.34
Step 42100: loss = 0.34 (0.365 sec) [273.98 data/s]
Step 42200: loss = 0.44 (0.363 sec) [275.28 data/s]
Step 42300: loss = 0.47 (0.363 sec) [275.55 data/s]
Step 42400: loss = 0.45 (0.363 sec) [275.43 data/s]
Step 42500: loss = 0.30 (0.363 sec) [275.35 data/s]
Step 42600: loss = 0.35 (0.369 sec) [271.18 data/s]
Step 42700: loss = 0.64 (0.363 sec) [275.76 data/s]
Step 42800: loss = 0.47 (0.363 sec) [275.50 data/s]
Step 42900: loss = 0.37 (0.365 sec) [274.13 data/s]
Step 43000: loss = 0.41 (0.365 sec) [274.19 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54125  Precision @ 1: 0.9021  Loss: 0.37
Validation Data Eval:
  Num examples: 10000  Num correct: 9088  Precision @ 1: 0.9088  Loss: 0.36
Step 43100: loss = 0.57 (0.363 sec) [275.77 data/s]
Step 43200: loss = 0.34 (0.363 sec) [275.30 data/s]
Step 43300: loss = 0.60 (0.364 sec) [274.65 data/s]
Step 43400: loss = 0.45 (0.363 sec) [275.32 data/s]
Step 43500: loss = 0.35 (0.363 sec) [275.60 data/s]
Step 43600: loss = 0.29 (0.363 sec) [275.65 data/s]
Step 43700: loss = 0.60 (0.365 sec) [273.88 data/s]
Step 43800: loss = 0.48 (0.363 sec) [275.55 data/s]
Step 43900: loss = 0.51 (0.364 sec) [274.76 data/s]
Step 44000: loss = 0.32 (0.363 sec) [275.30 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54135  Precision @ 1: 0.9022  Loss: 0.36
Validation Data Eval:
  Num examples: 10000  Num correct: 9048  Precision @ 1: 0.9048  Loss: 0.36
Step 44100: loss = 0.50 (0.363 sec) [275.30 data/s]
Step 44200: loss = 0.44 (0.363 sec) [275.54 data/s]
Step 44300: loss = 0.41 (0.363 sec) [275.61 data/s]
Step 44400: loss = 0.35 (0.367 sec) [272.61 data/s]
Step 44500: loss = 0.46 (0.362 sec) [276.03 data/s]
Step 44600: loss = 0.32 (0.362 sec) [275.88 data/s]
Step 44700: loss = 0.49 (0.363 sec) [275.66 data/s]
Step 44800: loss = 0.33 (0.363 sec) [275.59 data/s]
Step 44900: loss = 0.28 (0.365 sec) [274.22 data/s]
Step 45000: loss = 0.33 (0.364 sec) [274.91 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54225  Precision @ 1: 0.9038  Loss: 0.35
Validation Data Eval:
  Num examples: 10000  Num correct: 9071  Precision @ 1: 0.9071  Loss: 0.35
Step 45100: loss = 0.36 (0.363 sec) [275.32 data/s]
Step 45200: loss = 0.64 (0.363 sec) [275.23 data/s]
Step 45300: loss = 0.33 (0.363 sec) [275.27 data/s]
Step 45400: loss = 0.26 (0.363 sec) [275.24 data/s]
Step 45500: loss = 0.39 (0.363 sec) [275.61 data/s]
Step 45600: loss = 0.50 (0.363 sec) [275.60 data/s]
Step 45700: loss = 0.39 (0.363 sec) [275.49 data/s]
Step 45800: loss = 0.33 (0.363 sec) [275.86 data/s]
Step 45900: loss = 0.39 (0.364 sec) [275.08 data/s]
Step 46000: loss = 0.51 (0.362 sec) [275.92 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54066  Precision @ 1: 0.9011  Loss: 0.37
Validation Data Eval:
  Num examples: 10000  Num correct: 9056  Precision @ 1: 0.9056  Loss: 0.35
Step 46100: loss = 0.50 (0.363 sec) [275.64 data/s]
Step 46200: loss = 0.31 (0.364 sec) [275.02 data/s]
Step 46300: loss = 0.50 (0.362 sec) [275.94 data/s]
Step 46400: loss = 0.40 (0.362 sec) [275.91 data/s]
Step 46500: loss = 0.41 (0.365 sec) [273.90 data/s]
Step 46600: loss = 0.31 (0.363 sec) [275.53 data/s]
Step 46700: loss = 0.41 (0.362 sec) [276.08 data/s]
Step 46800: loss = 0.36 (0.364 sec) [275.05 data/s]
Step 46900: loss = 0.37 (0.362 sec) [276.00 data/s]
Step 47000: loss = 0.50 (0.365 sec) [274.27 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53778  Precision @ 1: 0.8963  Loss: 0.38
Validation Data Eval:
  Num examples: 10000  Num correct: 9019  Precision @ 1: 0.9019  Loss: 0.37
Step 47100: loss = 0.67 (0.363 sec) [275.17 data/s]
Step 47200: loss = 0.51 (0.364 sec) [275.05 data/s]
Step 47300: loss = 0.41 (0.364 sec) [274.82 data/s]
Step 47400: loss = 0.58 (0.363 sec) [275.74 data/s]
Step 47500: loss = 0.43 (0.362 sec) [275.89 data/s]
Step 47600: loss = 0.36 (0.363 sec) [275.14 data/s]
Step 47700: loss = 0.87 (0.363 sec) [275.71 data/s]
Step 47800: loss = 0.60 (0.363 sec) [275.34 data/s]
Step 47900: loss = 0.45 (0.366 sec) [273.37 data/s]
Step 48000: loss = 0.30 (0.363 sec) [275.25 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54139  Precision @ 1: 0.9023  Loss: 0.35
Validation Data Eval:
  Num examples: 10000  Num correct: 9102  Precision @ 1: 0.9102  Loss: 0.34
Step 48100: loss = 0.49 (0.364 sec) [274.71 data/s]
Step 48200: loss = 0.62 (0.364 sec) [274.98 data/s]
Step 48300: loss = 0.41 (0.364 sec) [274.97 data/s]
Step 48400: loss = 0.52 (0.365 sec) [273.66 data/s]
Step 48500: loss = 0.57 (0.364 sec) [274.81 data/s]
Step 48600: loss = 0.50 (0.363 sec) [275.62 data/s]
Step 48700: loss = 0.49 (0.364 sec) [274.96 data/s]
Step 48800: loss = 0.34 (0.363 sec) [275.17 data/s]
Step 48900: loss = 0.57 (0.363 sec) [275.24 data/s]
Step 49000: loss = 0.50 (0.364 sec) [275.08 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 53978  Precision @ 1: 0.8996  Loss: 0.37
Validation Data Eval:
  Num examples: 10000  Num correct: 9037  Precision @ 1: 0.9037  Loss: 0.36
Step 49100: loss = 0.29 (0.363 sec) [275.47 data/s]
Step 49200: loss = 0.55 (0.365 sec) [274.35 data/s]
Step 49300: loss = 0.58 (0.364 sec) [274.99 data/s]
Step 49400: loss = 0.36 (0.365 sec) [273.77 data/s]
Step 49500: loss = 0.67 (0.364 sec) [274.91 data/s]
Step 49600: loss = 0.58 (0.363 sec) [275.55 data/s]
Step 49700: loss = 0.39 (0.364 sec) [275.04 data/s]
Step 49800: loss = 0.30 (0.363 sec) [275.57 data/s]
Step 49900: loss = 0.53 (0.363 sec) [275.20 data/s]
Step 50000: loss = 0.44 (0.364 sec) [275.10 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54299  Precision @ 1: 0.9050  Loss: 0.34
Validation Data Eval:
  Num examples: 10000  Num correct: 9058  Precision @ 1: 0.9058  Loss: 0.34
Step 50100: loss = 0.36 (0.363 sec) [275.19 data/s]
Step 50200: loss = 0.69 (0.363 sec) [275.31 data/s]
Step 50300: loss = 0.41 (0.363 sec) [275.11 data/s]
Step 50400: loss = 0.57 (0.363 sec) [275.20 data/s]
Step 50500: loss = 0.29 (0.364 sec) [274.91 data/s]
Step 50600: loss = 0.48 (0.364 sec) [274.84 data/s]
Step 50700: loss = 0.70 (0.364 sec) [274.92 data/s]
Step 50800: loss = 0.44 (0.364 sec) [274.62 data/s]
Step 50900: loss = 0.34 (0.364 sec) [274.86 data/s]
Step 51000: loss = 0.38 (0.363 sec) [275.18 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54439  Precision @ 1: 0.9073  Loss: 0.34
Validation Data Eval:
  Num examples: 10000  Num correct: 9113  Precision @ 1: 0.9113  Loss: 0.33
Step 51100: loss = 0.42 (0.364 sec) [274.79 data/s]
Step 51200: loss = 0.44 (0.363 sec) [275.37 data/s]
Step 51300: loss = 0.52 (0.363 sec) [275.32 data/s]
Step 51400: loss = 0.49 (0.363 sec) [275.21 data/s]
Step 51500: loss = 0.38 (0.363 sec) [275.15 data/s]
Step 51600: loss = 0.41 (0.364 sec) [275.05 data/s]
Step 51700: loss = 0.46 (0.363 sec) [275.41 data/s]
Step 51800: loss = 0.35 (0.365 sec) [273.70 data/s]
Step 51900: loss = 0.61 (0.363 sec) [275.13 data/s]
Step 52000: loss = 0.46 (0.364 sec) [274.68 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54004  Precision @ 1: 0.9001  Loss: 0.36
Validation Data Eval:
  Num examples: 10000  Num correct: 9025  Precision @ 1: 0.9025  Loss: 0.36
Step 52100: loss = 0.47 (0.366 sec) [273.28 data/s]
Step 52200: loss = 0.40 (0.363 sec) [275.29 data/s]
Step 52300: loss = 0.34 (0.363 sec) [275.21 data/s]
Step 52400: loss = 0.53 (0.364 sec) [274.41 data/s]
Step 52500: loss = 0.37 (0.364 sec) [274.82 data/s]
Step 52600: loss = 0.39 (0.363 sec) [275.15 data/s]
Step 52700: loss = 0.50 (0.363 sec) [275.68 data/s]
Step 52800: loss = 0.52 (0.363 sec) [275.45 data/s]
Step 52900: loss = 0.41 (0.363 sec) [275.19 data/s]
Step 53000: loss = 0.69 (0.363 sec) [275.34 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54042  Precision @ 1: 0.9007  Loss: 0.36
Validation Data Eval:
  Num examples: 10000  Num correct: 9046  Precision @ 1: 0.9046  Loss: 0.35
Step 53100: loss = 0.40 (0.363 sec) [275.34 data/s]
Step 53200: loss = 0.37 (0.364 sec) [275.00 data/s]
Step 53300: loss = 0.64 (0.363 sec) [275.21 data/s]
Step 53400: loss = 0.38 (0.363 sec) [275.54 data/s]
Step 53500: loss = 0.29 (0.364 sec) [274.83 data/s]
Step 53600: loss = 0.26 (0.365 sec) [273.97 data/s]
Step 53700: loss = 0.42 (0.364 sec) [275.05 data/s]
Step 53800: loss = 0.54 (0.363 sec) [275.59 data/s]
Step 53900: loss = 0.38 (0.364 sec) [274.86 data/s]
Step 54000: loss = 0.47 (0.364 sec) [274.86 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54056  Precision @ 1: 0.9009  Loss: 0.36
Validation Data Eval:
  Num examples: 10000  Num correct: 9030  Precision @ 1: 0.9030  Loss: 0.35
Step 54100: loss = 0.49 (0.364 sec) [274.50 data/s]
Step 54200: loss = 0.45 (0.363 sec) [275.43 data/s]
Step 54300: loss = 0.51 (0.364 sec) [274.86 data/s]
Step 54400: loss = 0.39 (0.364 sec) [274.99 data/s]
Step 54500: loss = 0.63 (0.364 sec) [275.08 data/s]
Step 54600: loss = 0.49 (0.363 sec) [275.44 data/s]
Step 54700: loss = 0.65 (0.363 sec) [275.27 data/s]
Step 54800: loss = 0.39 (0.363 sec) [275.13 data/s]
Step 54900: loss = 0.34 (0.364 sec) [274.72 data/s]
Step 55000: loss = 0.44 (0.364 sec) [274.84 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54191  Precision @ 1: 0.9032  Loss: 0.36
Validation Data Eval:
  Num examples: 10000  Num correct: 9088  Precision @ 1: 0.9088  Loss: 0.34
Step 55100: loss = 0.39 (0.364 sec) [275.05 data/s]
Step 55200: loss = 0.35 (0.365 sec) [274.23 data/s]
Step 55300: loss = 0.44 (0.364 sec) [274.79 data/s]
Step 55400: loss = 0.29 (0.364 sec) [274.93 data/s]
Step 55500: loss = 0.39 (0.362 sec) [276.06 data/s]
Step 55600: loss = 0.32 (0.363 sec) [275.63 data/s]
Step 55700: loss = 0.45 (0.363 sec) [275.33 data/s]
Step 55800: loss = 0.44 (0.364 sec) [274.62 data/s]
Step 55900: loss = 0.58 (0.364 sec) [275.09 data/s]
Step 56000: loss = 0.41 (0.365 sec) [274.22 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54254  Precision @ 1: 0.9042  Loss: 0.35
Validation Data Eval:
  Num examples: 10000  Num correct: 9093  Precision @ 1: 0.9093  Loss: 0.34
Step 56100: loss = 0.45 (0.365 sec) [273.92 data/s]
Step 56200: loss = 0.53 (0.363 sec) [275.44 data/s]
Step 56300: loss = 0.61 (0.364 sec) [275.10 data/s]
Step 56400: loss = 0.46 (0.363 sec) [275.16 data/s]
Step 56500: loss = 0.33 (0.365 sec) [273.84 data/s]
Step 56600: loss = 0.43 (0.363 sec) [275.39 data/s]
Step 56700: loss = 0.34 (0.365 sec) [273.63 data/s]
Step 56800: loss = 0.51 (0.363 sec) [275.84 data/s]
Step 56900: loss = 0.48 (0.366 sec) [273.23 data/s]
Step 57000: loss = 0.32 (0.364 sec) [275.04 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54384  Precision @ 1: 0.9064  Loss: 0.34
Validation Data Eval:
  Num examples: 10000  Num correct: 9085  Precision @ 1: 0.9085  Loss: 0.34
Step 57100: loss = 0.41 (0.364 sec) [274.86 data/s]
Step 57200: loss = 0.51 (0.365 sec) [273.77 data/s]
Step 57300: loss = 0.44 (0.363 sec) [275.61 data/s]
Step 57400: loss = 0.51 (0.364 sec) [274.79 data/s]
Step 57500: loss = 0.39 (0.363 sec) [275.76 data/s]
Step 57600: loss = 0.42 (0.363 sec) [275.33 data/s]
Step 57700: loss = 0.48 (0.364 sec) [274.37 data/s]
Step 57800: loss = 0.31 (0.363 sec) [275.47 data/s]
Step 57900: loss = 0.31 (0.363 sec) [275.14 data/s]
Step 58000: loss = 0.42 (0.363 sec) [275.51 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54149  Precision @ 1: 0.9025  Loss: 0.35
Validation Data Eval:
  Num examples: 10000  Num correct: 9055  Precision @ 1: 0.9055  Loss: 0.34
Step 58100: loss = 0.36 (0.363 sec) [275.55 data/s]
Step 58200: loss = 0.47 (0.362 sec) [276.00 data/s]
Step 58300: loss = 0.33 (0.365 sec) [274.25 data/s]
Step 58400: loss = 0.32 (0.363 sec) [275.12 data/s]
Step 58500: loss = 0.36 (0.364 sec) [274.97 data/s]
Step 58600: loss = 0.31 (0.363 sec) [275.20 data/s]
Step 58700: loss = 0.42 (0.365 sec) [273.79 data/s]
Step 58800: loss = 0.46 (0.363 sec) [275.41 data/s]
Step 58900: loss = 0.42 (0.363 sec) [275.65 data/s]
Step 59000: loss = 0.35 (0.363 sec) [275.23 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54161  Precision @ 1: 0.9027  Loss: 0.36
Validation Data Eval:
  Num examples: 10000  Num correct: 9083  Precision @ 1: 0.9083  Loss: 0.34
Step 59100: loss = 0.41 (0.364 sec) [275.03 data/s]
Step 59200: loss = 0.41 (0.363 sec) [275.69 data/s]
Step 59300: loss = 0.47 (0.364 sec) [275.03 data/s]
Step 59400: loss = 0.26 (0.363 sec) [275.34 data/s]
Step 59500: loss = 0.39 (0.362 sec) [275.97 data/s]
Step 59600: loss = 0.50 (0.364 sec) [274.46 data/s]
Step 59700: loss = 0.35 (0.363 sec) [275.40 data/s]
Step 59800: loss = 0.41 (0.363 sec) [275.79 data/s]
Step 59900: loss = 0.50 (0.363 sec) [275.77 data/s]
Step 60000: loss = 0.47 (0.363 sec) [275.65 data/s]
Training Data Eval:
  Num examples: 60000  Num correct: 54549  Precision @ 1: 0.9092  Loss: 0.34
Validation Data Eval:
  Num examples: 10000  Num correct: 9124  Precision @ 1: 0.9124  Loss: 0.32